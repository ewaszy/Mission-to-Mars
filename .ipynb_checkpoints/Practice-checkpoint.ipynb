{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cb3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scraping tools\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7721b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\ewaas\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Set up Splinter (set the executable path)\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "# Initialize the Chrome browser in Splinter\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de6ee4",
   "metadata": {},
   "source": [
    "# Scrape The Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a6932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Quotes to Scrape site\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3328db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0fcbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top Ten tags'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the Title\n",
    "title = html_soup.find('h2').text\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f617129",
   "metadata": {},
   "source": [
    "# Scrape all of the Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67dbc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# Scrape the top ten tags\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "# tag_box\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "# For loop that cycles through each tag in the list\n",
    "for tag in tags:\n",
    "    # Strips the HTML from the code and assigns result to a variable\n",
    "    word = tag.text\n",
    "    # Prints each word in the list\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a70d1",
   "metadata": {},
   "source": [
    "# Scrape across pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89777cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already created this, but we can add it if we'd like to create the Browser instance again\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for loop that will do the following:\n",
    "    #Create a BeautifulSoup object\n",
    "    #Find all the quotes on the page\n",
    "    #Print each quote from the page\n",
    "    #Click the \"Next\" button at the bottom of the page\n",
    "\n",
    "# Use range(1, 6) to visit the first 5 pages of the website - 5 iterations\n",
    "for x in range(1, 6):\n",
    "    # Create an HTML object, assigned to the HTML variable\n",
    "    html = browser.html\n",
    "    # Use BeautifulSoup to parse the HTML object\n",
    "    quote_soup = soup(html, 'html.parser')\n",
    "    # Use BeautifulSoup to find all <span /> tags with a call of \"text\"\n",
    "    quotes = quote_soup.find_all('span', class_='text')\n",
    "    for quote in quotes:\n",
    "        print('page:', x, '----------')\n",
    "        # Print statements wrapped in another for loop that will prin each quote parsed by BeautifulSoup\n",
    "        print(quote.text)\n",
    "    # Use Splinter to click the \"Next\" button    \n",
    "    browser.links.find_by_partial_text('Next').click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
